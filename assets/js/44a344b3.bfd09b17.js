"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[299],{9354:(e,s,r)=>{r.r(s),r.d(s,{assets:()=>l,contentTitle:()=>n,default:()=>a,frontMatter:()=>d,metadata:()=>h,toc:()=>c});var t=r(5893),i=r(1151);const d={title:"Lectures"},n=void 0,h={type:"mdx",permalink:"/lectures",source:"@site/src/pages/lectures.md",title:"Lectures",description:"Course Schedule",frontMatter:{title:"Lectures"},unlisted:!1},l={},c=[{value:"Course Schedule",id:"course-schedule",level:2}];function o(e){const s={a:"a",h2:"h2",p:"p",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",...(0,i.a)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(s.h2,{id:"course-schedule",children:"Course Schedule"}),"\n",(0,t.jsxs)(s.p,{children:["Lecture slides are posted here and on ",(0,t.jsx)(s.a,{href:"https://piazza.com/cmu/spring2024/16831/resources",children:"Piazza"}),". All due dates are at 11:59 PM ET."]}),"\n",(0,t.jsxs)(s.table,{children:[(0,t.jsx)(s.thead,{children:(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.th,{children:"Date"}),(0,t.jsx)(s.th,{children:"Lecture"}),(0,t.jsx)(s.th,{children:"Optional Readings"}),(0,t.jsx)(s.th,{children:"Logistics"}),(0,t.jsx)(s.th,{children:"Topic Groups"})]})}),(0,t.jsxs)(s.tbody,{children:[(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.td,{children:"1/15"}),(0,t.jsx)(s.td,{children:"Holiday (MLK Jr. Day)"}),(0,t.jsx)(s.td,{}),(0,t.jsx)(s.td,{}),(0,t.jsx)(s.td,{})]}),(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.td,{children:"1/17"}),(0,t.jsxs)(s.td,{children:["Lecture 1: Course Introduction: What is Robot Learning? [",(0,t.jsx)(s.a,{href:"https://drive.google.com/file/d/11x75_ww4HkCM1o9RnI1bOsEfGQCktzTa/view?usp=drive_link",children:"slides"}),"]"]}),(0,t.jsxs)(s.td,{children:["[",(0,t.jsx)(s.a,{href:"https://arxiv.org/abs/1604.00289",children:"Building Machines That Learn and Think Like People"}),"]"]}),(0,t.jsx)(s.td,{}),(0,t.jsx)(s.td,{children:"\ud83d\udd34 Introduction"})]}),(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.td,{children:"1/22"}),(0,t.jsxs)(s.td,{children:["Lecture 2: Robot Learning: An Overview [",(0,t.jsx)(s.a,{href:"https://drive.google.com/file/d/1QDk8n7lS8OGzxtBjT3HB5Zor1W-mvj0b/view?usp=sharing",children:"slides"}),"]"]}),(0,t.jsxs)(s.td,{children:["[",(0,t.jsx)(s.a,{href:"http://incompleteideas.net/book/RLbook2018.pdf",children:"RL Textbook, Ch 1"}),"]"]}),(0,t.jsx)(s.td,{}),(0,t.jsx)(s.td,{children:"\ud83d\udd34 Introduction"})]}),(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.td,{children:"1/24"}),(0,t.jsxs)(s.td,{children:["Lecture 3: ML/DL Refresher Part 1 [",(0,t.jsx)(s.a,{href:"https://drive.google.com/file/d/13hNMCDQqBLyfmh2NyJyN30gcJw0naFg-/view?usp=sharing",children:"slides"}),"]"]}),(0,t.jsxs)(s.td,{children:["[",(0,t.jsx)(s.a,{href:"https://www.deeplearningbook.org/",children:"DL Textbook, Ch 5-10"}),"]"]}),(0,t.jsx)(s.td,{children:"HW1 Out"}),(0,t.jsx)(s.td,{children:"\ud83d\udfe0 ML/DL Refresher"})]}),(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.td,{children:"1/29"}),(0,t.jsxs)(s.td,{children:["Lecture 4: ML/DL Refresher Part 2 [",(0,t.jsx)(s.a,{href:"https://drive.google.com/file/d/1ZdsWc88YPYY45YYAdgdD2Szbto-mQOLS/view?usp=sharing",children:"slides"}),"]"]}),(0,t.jsxs)(s.td,{children:["[",(0,t.jsx)(s.a,{href:"https://www.deeplearningbook.org/",children:"DL Textbook, Ch 5-10"}),"]"]}),(0,t.jsx)(s.td,{}),(0,t.jsx)(s.td,{children:"\ud83d\udfe0 ML/DL Refresher"})]}),(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.td,{children:"1/31"}),(0,t.jsxs)(s.td,{children:["Lecture 5: MDP Basics and Imitation Learning Part 1 [",(0,t.jsx)(s.a,{href:"https://drive.google.com/file/d/18CEtu18G6OheNlhbXT6Sw-Smu5jDqAIA/view?usp=sharing",children:"slides"}),"]"]}),(0,t.jsxs)(s.td,{children:["[",(0,t.jsx)(s.a,{href:"https://sites.google.com/view/icml2018-imitation-learning/",children:"ICML Tutorial"}),"][",(0,t.jsx)(s.a,{href:"https://www.ri.cmu.edu/pub_files/2015/3/InvitationToImitation_3_1415.pdf",children:"An Invitation to Imitation"}),"]"]}),(0,t.jsx)(s.td,{}),(0,t.jsx)(s.td,{children:"\ud83d\udfe3 Imitation Learning"})]}),(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.td,{children:"2/05"}),(0,t.jsxs)(s.td,{children:["Lecture 6: Imitation Learning Part 2 [",(0,t.jsx)(s.a,{href:"https://drive.google.com/file/d/1Av8vmiKNF_sGsNABvtBnwxOjQYn4gFBn/view?usp=sharing",children:"slides"}),"]"]}),(0,t.jsxs)(s.td,{children:["[",(0,t.jsx)(s.a,{href:"https://arxiv.org/pdf/1011.0686.pdf",children:"DAgger"}),"][",(0,t.jsx)(s.a,{href:"https://arxiv.org/pdf/1606.03476.pdf",children:"GAIL"}),"][",(0,t.jsx)(s.a,{href:"https://diffusion-policy.cs.columbia.edu/",children:"Diffusion Policy"}),"][",(0,t.jsx)(s.a,{href:"https://arxiv.org/abs/2010.14406",children:"Transporter"}),"]"]}),(0,t.jsx)(s.td,{}),(0,t.jsx)(s.td,{children:"\ud83d\udfe3 Imitation Learning"})]}),(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.td,{children:"2/07"}),(0,t.jsxs)(s.td,{children:["Lecture 7: RL Basics: Value/Policy Iteration [",(0,t.jsx)(s.a,{href:"https://drive.google.com/file/d/1c8k6H1o3Q-8LjuSWR3IAs_5Q4oGUcV9t/view?usp=sharing",children:"slides"}),"]"]}),(0,t.jsxs)(s.td,{children:["[",(0,t.jsx)(s.a,{href:"http://incompleteideas.net/book/RLbook2018.pdf",children:"RL Textbook, Ch 3-4"}),"][",(0,t.jsx)(s.a,{href:"https://spinningup.openai.com/en/latest/spinningup/rl_intro.html",children:"Key Concepts in RL"}),"][",(0,t.jsx)(s.a,{href:"https://spinningup.openai.com/en/latest/spinningup/rl_intro2.html",children:"Kinds of RL Algorithms"}),"]"]}),(0,t.jsx)(s.td,{}),(0,t.jsx)(s.td,{children:"\ud83d\udfe2 Model-Free RL"})]}),(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.td,{children:"2/12"}),(0,t.jsxs)(s.td,{children:["Lecture 8: Q-Learning and Variants [",(0,t.jsx)(s.a,{href:"https://drive.google.com/file/d/1g7T9gk8xJuGYNxrqfV5LjDcKSvwuEEqJ/view?usp=sharing",children:"slides"}),"]"]}),(0,t.jsxs)(s.td,{children:["[",(0,t.jsx)(s.a,{href:"http://incompleteideas.net/book/RLbook2018.pdf",children:"RL Textbook, Ch 5-7"}),"][",(0,t.jsx)(s.a,{href:"https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf",children:"DQN"}),"]"]}),(0,t.jsx)(s.td,{children:"HW1 Due; HW2 Out"}),(0,t.jsx)(s.td,{children:"\ud83d\udfe2 Model-Free RL"})]}),(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.td,{children:"2/14"}),(0,t.jsxs)(s.td,{children:["Lecture 9: Policy Gradient Methods [",(0,t.jsx)(s.a,{href:"https://drive.google.com/file/d/1YyHzF8p59kkTqTHSf0qUWJZC6_Z_ab14/view?usp=sharing",children:"slides"}),"]"]}),(0,t.jsxs)(s.td,{children:["[",(0,t.jsx)(s.a,{href:"http://incompleteideas.net/book/RLbook2018.pdf",children:"RL Textbook, Ch 13"}),"][",(0,t.jsx)(s.a,{href:"https://spinningup.openai.com/en/latest/spinningup/rl_intro3.html",children:"Intro to Policy Gradient"}),"]"]}),(0,t.jsx)(s.td,{}),(0,t.jsx)(s.td,{children:"\ud83d\udfe2 Model-Free RL"})]}),(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.td,{children:"2/19"}),(0,t.jsxs)(s.td,{children:["Lecture 10: Actor-Critic Methods [",(0,t.jsx)(s.a,{href:"https://drive.google.com/file/d/1YbnowC7YMjhwsj5zrfXbl7DV-yFHzDPf/view?usp=sharing",children:"slides"}),"]"]}),(0,t.jsxs)(s.td,{children:["[",(0,t.jsx)(s.a,{href:"http://incompleteideas.net/book/RLbook2018.pdf",children:"RL Textbook, Ch 13"}),"]"]}),(0,t.jsx)(s.td,{}),(0,t.jsx)(s.td,{children:"\ud83d\udfe2 Model-Free RL"})]}),(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.td,{children:"2/21"}),(0,t.jsxs)(s.td,{children:["Lecture 11: Advanced RL Algorithms [",(0,t.jsx)(s.a,{href:"https://drive.google.com/file/d/1OU9rojK1RelIhwQILuq9BQkgscs_E7ec/view?usp=sharing",children:"slides"}),"]"]}),(0,t.jsxs)(s.td,{children:["[",(0,t.jsx)(s.a,{href:"https://arxiv.org/pdf/1707.06347",children:"PPO"}),"][",(0,t.jsx)(s.a,{href:"https://arxiv.org/pdf/1502.05477.pdf",children:"TRPO"}),"][",(0,t.jsx)(s.a,{href:"https://arxiv.org/pdf/1509.02971.pdf",children:"DDPG"}),"][",(0,t.jsx)(s.a,{href:"https://arxiv.org/abs/1801.01290",children:"SAC"}),"]"]}),(0,t.jsx)(s.td,{}),(0,t.jsx)(s.td,{children:"\ud83d\udfe2 Model-Free RL"})]}),(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.td,{children:"2/26"}),(0,t.jsxs)(s.td,{children:["Lecture 12: Model-Based Control Basics [",(0,t.jsx)(s.a,{href:"https://drive.google.com/file/d/1nOU6DFTxPdLBFysIIt21PeiHDyhQIHrG/view?usp=sharing",children:"slides"}),"]"]}),(0,t.jsxs)(s.td,{children:["[",(0,t.jsx)(s.a,{href:"https://fbswiki.org/wiki/index.php/Feedback_Systems:_An_Introduction_for_Scientists_and_Engineers",children:"Feedback Systems Textbook"}),"]"]}),(0,t.jsx)(s.td,{children:"HW2 Due; HW3 Out"}),(0,t.jsx)(s.td,{children:"\ud83d\udd35 Model-Based RL"})]}),(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.td,{children:"2/28"}),(0,t.jsxs)(s.td,{children:["Lecture 13: Optimal Control and Planning Part 1 [",(0,t.jsx)(s.a,{href:"https://drive.google.com/file/d/1OyDhL4finUa7XO6r72XuM3_DymIwVyNZ/view?usp=sharing",children:"slides"}),"]"]}),(0,t.jsxs)(s.td,{children:["[",(0,t.jsx)(s.a,{href:"https://fbswiki.org/wiki/index.php/Supplement:_Optimization-Based_Control",children:"Murray's Notes"}),"][",(0,t.jsx)(s.a,{href:"https://www.scitepress.org/PublishedPapers/2004/11439/pdf/index.html",children:"iLQR"}),"][",(0,t.jsx)(s.a,{href:"https://ieeexplore.ieee.org/abstract/document/6386025",children:"DDP"}),"][",(0,t.jsx)(s.a,{href:"https://arc.aiaa.org/doi/epdf/10.2514/1.G000218",children:"SCP"}),"]"]}),(0,t.jsx)(s.td,{}),(0,t.jsx)(s.td,{children:"\ud83d\udd35 Model-Based RL"})]}),(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.td,{children:"3/04"}),(0,t.jsx)(s.td,{children:"Spring Break"}),(0,t.jsx)(s.td,{}),(0,t.jsx)(s.td,{}),(0,t.jsx)(s.td,{})]}),(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.td,{children:"3/06"}),(0,t.jsx)(s.td,{children:"Spring Break"}),(0,t.jsx)(s.td,{}),(0,t.jsx)(s.td,{}),(0,t.jsx)(s.td,{})]}),(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.td,{children:"3/11"}),(0,t.jsxs)(s.td,{children:["Lecture 14: Optimal Control and Planning Part 2 [",(0,t.jsx)(s.a,{href:"https://drive.google.com/file/d/1OyDhL4finUa7XO6r72XuM3_DymIwVyNZ/view?usp=sharing",children:"slides"}),"]"]}),(0,t.jsxs)(s.td,{children:["[",(0,t.jsx)(s.a,{href:"https://arxiv.org/abs/1805.12114",children:"PETS"}),"][",(0,t.jsx)(s.a,{href:"https://www.gshi.me/blog/NeuralControl/",children:"Neural-Control Family"}),"][",(0,t.jsx)(s.a,{href:"https://homes.cs.washington.edu/~bboots/files/InformationTheoreticMPC.pdf",children:"MPPI"}),"][",(0,t.jsx)(s.a,{href:"https://www.cs.utexas.edu/users/sniekum/classes/RLFD-F15/papers/Deisenroth11.pdf",children:"PILCO"}),"][",(0,t.jsx)(s.a,{href:"https://arxiv.org/pdf/1906.08253.pdf",children:"MBPO"}),"]"]}),(0,t.jsx)(s.td,{}),(0,t.jsx)(s.td,{children:"\ud83d\udd35 Model-Based RL"})]}),(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.td,{children:"3/13"}),(0,t.jsxs)(s.td,{children:["Lecture 15: Deep Model-Based RL [",(0,t.jsx)(s.a,{href:"https://drive.google.com/file/d/1AfaWh5euI4Os2uBAl7r962r6YGxico0g/view?usp=sharing",children:"slides"}),"]"]}),(0,t.jsxs)(s.td,{children:["[",(0,t.jsx)(s.a,{href:"https://arxiv.org/pdf/1912.01603.pdf",children:"Dreamer"}),"][",(0,t.jsx)(s.a,{href:"https://nicklashansen.github.io/td-mpc/",children:"TD-MPC"}),"]"]}),(0,t.jsx)(s.td,{children:"HW3 Due; HW4 Out"}),(0,t.jsx)(s.td,{children:"\ud83d\udd35 Model-Based RL"})]}),(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.td,{children:"3/18"}),(0,t.jsxs)(s.td,{children:["Lecture 16: Guest Lecture: Learning Structured World Models From and For Physical Interactions (",(0,t.jsx)(s.a,{href:"https://yunzhuli.github.io/",children:"Yunzhu Li"}),") [",(0,t.jsx)(s.a,{href:"https://drive.google.com/file/d/1wk7QzvpRGgR2l-m47CV-tyva3TjH3t5Y/view?usp=sharing",children:"slides"}),"]"]}),(0,t.jsxs)(s.td,{children:["[",(0,t.jsx)(s.a,{href:"https://hshi74.github.io/robocook/",children:"RoboCook"}),"][",(0,t.jsx)(s.a,{href:"https://robopil.github.io/dyn-res-pile-manip/",children:"DynRes"}),"][",(0,t.jsx)(s.a,{href:"https://robopil.github.io/Sparse-Dynamics/",children:"SparseDyn"}),"][",(0,t.jsx)(s.a,{href:"http://dpi.csail.mit.edu/",children:"DPI-Net"}),"]"]}),(0,t.jsx)(s.td,{}),(0,t.jsx)(s.td,{children:"\ud83d\udd35 Model-Based RL"})]}),(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.td,{children:"3/20"}),(0,t.jsxs)(s.td,{children:["Lecture 17: Guest Lecture: Offline RL (",(0,t.jsx)(s.a,{href:"https://aviralkumar2907.github.io/",children:"Aviral Kumar"}),") [",(0,t.jsx)(s.a,{href:"https://drive.google.com/file/d/1A8Ds26E_i1Y-x6LUitnTS4N9VSAC_qQ5/view?usp=sharing",children:"slides"}),"]"]}),(0,t.jsxs)(s.td,{children:["[",(0,t.jsx)(s.a,{href:"https://sites.google.com/view/offlinerltutorial-neurips2020/home",children:"NeurIPS Tutorial"}),"][",(0,t.jsx)(s.a,{href:"https://arxiv.org/abs/2110.06169",children:"IQL"}),"][",(0,t.jsx)(s.a,{href:"https://arxiv.org/abs/2205.09991",children:"Diffuser"}),"]"]}),(0,t.jsx)(s.td,{}),(0,t.jsx)(s.td,{children:"\u26aa RL from Offline Data"})]}),(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.td,{children:"3/25"}),(0,t.jsxs)(s.td,{children:["Lecture 18: Inverse RL [",(0,t.jsx)(s.a,{href:"https://drive.google.com/file/d/1_Mm96iscd10zhN4eK4fbnGqzHZpceV1h/view?usp=sharing",children:"slides"}),"]"]}),(0,t.jsxs)(s.td,{children:["[",(0,t.jsx)(s.a,{href:"https://cdn.aaai.org/AAAI/2008/AAAI08-227.pdf",children:"Maximum Entropy IRL"}),"][",(0,t.jsx)(s.a,{href:"https://ai.stanford.edu/~ang/papers/icml00-irl.pdf",children:"LP-IRL"}),"]"]}),(0,t.jsx)(s.td,{children:"Project Proposal Due"}),(0,t.jsx)(s.td,{children:"\u26aa RL from Offline Data"})]}),(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.td,{children:"3/27"}),(0,t.jsx)(s.td,{children:"Lecture 19: Bandits and Preference-Based Learning"}),(0,t.jsxs)(s.td,{children:["[",(0,t.jsx)(s.a,{href:"http://incompleteideas.net/book/RLbook2018.pdf",children:"RL Textbook, Ch 2"}),"][",(0,t.jsx)(s.a,{href:"https://www.cs.cornell.edu/people/tj/publications/yue_etal_09a.pdf",children:"Dueling Bandits"}),"]"]}),(0,t.jsx)(s.td,{}),(0,t.jsx)(s.td,{children:"\ud83d\udfe1 Bandits and Exploration"})]}),(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.td,{children:"4/01"}),(0,t.jsx)(s.td,{children:"Lecture 20: Exploration"}),(0,t.jsxs)(s.td,{children:["[",(0,t.jsx)(s.a,{href:"https://arxiv.org/pdf/1705.05363.pdf",children:"Curiosity"}),"][",(0,t.jsx)(s.a,{href:"https://arxiv.org/pdf/1810.12894.pdf",children:"RND"}),"]"]}),(0,t.jsx)(s.td,{}),(0,t.jsx)(s.td,{children:"\ud83d\udfe1 Bandits and Exploration"})]}),(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.td,{children:"4/03"}),(0,t.jsx)(s.td,{children:"Lecture 21: Safe RL and Safe Robot Learning"}),(0,t.jsxs)(s.td,{children:["[",(0,t.jsx)(s.a,{href:"https://www.annualreviews.org/doi/abs/10.1146/annurev-control-042920-020211",children:"Safe Robot Learning Survey"}),"][",(0,t.jsx)(s.a,{href:"https://ieeexplore.ieee.org/abstract/document/10266799",children:"Data-Driven Safety Filters"}),"]"]}),(0,t.jsx)(s.td,{}),(0,t.jsx)(s.td,{children:"\ud83d\udfe4 Specialized Topics"})]}),(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.td,{children:"4/08"}),(0,t.jsx)(s.td,{children:"Lecture 22: Robot Simulation and Sim2Real"}),(0,t.jsxs)(s.td,{children:["[",(0,t.jsx)(s.a,{href:"https://arxiv.org/abs/1703.06907",children:"Domain Randomization"}),"][",(0,t.jsx)(s.a,{href:"https://www.nature.com/articles/s41586-023-06419-4",children:"Champion-Level Drone Racing"}),"]"]}),(0,t.jsx)(s.td,{children:"HW4 Due"}),(0,t.jsx)(s.td,{children:"\ud83d\udfe4 Specialized Topics"})]}),(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.td,{children:"4/10"}),(0,t.jsx)(s.td,{children:"Lecture 23: Multi-Task/Adaptive/Transferable Robot Learning"}),(0,t.jsxs)(s.td,{children:["[",(0,t.jsx)(s.a,{href:"https://www.research-collection.ethz.ch/bitstream/handle/20.500.11850/448343/1/2020_science_robotics_lee_locomotion.pdf",children:"Teacher-Student"}),"][",(0,t.jsx)(s.a,{href:"https://arxiv.org/abs/2107.04034",children:"RMA"}),"][",(0,t.jsx)(s.a,{href:"https://arxiv.org/abs/2205.06908",children:"Neural-Fly"}),"]"]}),(0,t.jsx)(s.td,{}),(0,t.jsx)(s.td,{children:"\ud83d\udfe4 Specialized Topics"})]}),(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.td,{children:"4/15"}),(0,t.jsxs)(s.td,{children:["Lecture 24: Guest Lecture: Foundation Models in Robotics (",(0,t.jsx)(s.a,{href:"https://jeffreyyh.github.io/",children:"Yafei Hu"}),")"]}),(0,t.jsxs)(s.td,{children:["[",(0,t.jsx)(s.a,{href:"https://github.com/JeffreyYH/robotics-fm-survey",children:"Survey"}),"][",(0,t.jsx)(s.a,{href:"https://arxiv.org/abs/2204.01691",children:"SayCan"}),"][",(0,t.jsx)(s.a,{href:"https://arxiv.org/abs/2109.12098",children:"CLIPort"}),"][",(0,t.jsx)(s.a,{href:"https://arxiv.org/abs/2212.06817",children:"RT-1"}),"][",(0,t.jsx)(s.a,{href:"https://arxiv.org/abs/2209.07753",children:"Code as Policies"}),"]"]}),(0,t.jsx)(s.td,{}),(0,t.jsx)(s.td,{children:"\ud83d\udfe4 Specialized Topics"})]}),(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.td,{children:"4/17"}),(0,t.jsx)(s.td,{children:"Lecture 25: Student Project Presentations"}),(0,t.jsx)(s.td,{}),(0,t.jsx)(s.td,{}),(0,t.jsx)(s.td,{children:"\u26ab Project"})]}),(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.td,{children:"4/22"}),(0,t.jsx)(s.td,{children:"Lecture 26: Student Project Presentations"}),(0,t.jsx)(s.td,{}),(0,t.jsx)(s.td,{}),(0,t.jsx)(s.td,{children:"\u26ab Project"})]}),(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.td,{children:"4/24"}),(0,t.jsx)(s.td,{children:"Lecture 27: Student Project Poster Session"}),(0,t.jsx)(s.td,{}),(0,t.jsx)(s.td,{}),(0,t.jsx)(s.td,{children:"\u26ab Project"})]}),(0,t.jsxs)(s.tr,{children:[(0,t.jsx)(s.td,{children:"5/03"}),(0,t.jsx)(s.td,{}),(0,t.jsx)(s.td,{}),(0,t.jsx)(s.td,{children:"Project Report Due"}),(0,t.jsx)(s.td,{})]})]})]})]})}function a(e={}){const{wrapper:s}={...(0,i.a)(),...e.components};return s?(0,t.jsx)(s,{...e,children:(0,t.jsx)(o,{...e})}):o(e)}},1151:(e,s,r)=>{r.d(s,{Z:()=>h,a:()=>n});var t=r(7294);const i={},d=t.createContext(i);function n(e){const s=t.useContext(d);return t.useMemo((function(){return"function"==typeof e?e(s):{...s,...e}}),[s,e])}function h(e){let s;return s=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:n(e.components),t.createElement(d.Provider,{value:s},e.children)}}}]);